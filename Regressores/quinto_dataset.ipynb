{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['6', ' 2', ' 1036', ' 103', ' 114', ' 1.00', ' 1.00.1', ' 172076',\n",
       "       ' 355965', ' 2.0', ' 6527', ' 1851864', ' 90'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importando os dados\n",
    "import pandas as pd\n",
    "\n",
    "path = r'/home/lapisco/Desktop/ica/ICA/Dados/datasets/regressao/computer/data.csv'\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "data = pd.DataFrame(data)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>2</th>\n",
       "      <th>1036</th>\n",
       "      <th>103</th>\n",
       "      <th>114</th>\n",
       "      <th>1.00</th>\n",
       "      <th>1.00.1</th>\n",
       "      <th>172076</th>\n",
       "      <th>355965</th>\n",
       "      <th>2.0</th>\n",
       "      <th>6527</th>\n",
       "      <th>1851864</th>\n",
       "      <th>90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166021</td>\n",
       "      <td>0.037462</td>\n",
       "      <td>0.017251</td>\n",
       "      <td>0.019881</td>\n",
       "      <td>0.020148</td>\n",
       "      <td>0.016953</td>\n",
       "      <td>0.023688</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.006265</td>\n",
       "      <td>0.504608</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.033604</td>\n",
       "      <td>0.133913</td>\n",
       "      <td>0.298530</td>\n",
       "      <td>0.047440</td>\n",
       "      <td>0.029180</td>\n",
       "      <td>0.069583</td>\n",
       "      <td>0.023506</td>\n",
       "      <td>0.194692</td>\n",
       "      <td>0.148439</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.016789</td>\n",
       "      <td>0.586036</td>\n",
       "      <td>0.858586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002710</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.372416</td>\n",
       "      <td>0.047063</td>\n",
       "      <td>0.031198</td>\n",
       "      <td>0.049205</td>\n",
       "      <td>0.043318</td>\n",
       "      <td>0.207614</td>\n",
       "      <td>0.096363</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014868</td>\n",
       "      <td>0.433582</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.022764</td>\n",
       "      <td>0.095652</td>\n",
       "      <td>0.310078</td>\n",
       "      <td>0.045745</td>\n",
       "      <td>0.043494</td>\n",
       "      <td>0.129225</td>\n",
       "      <td>0.077233</td>\n",
       "      <td>0.077982</td>\n",
       "      <td>0.293147</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>0.023054</td>\n",
       "      <td>0.451948</td>\n",
       "      <td>0.797980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002710</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.127826</td>\n",
       "      <td>0.023720</td>\n",
       "      <td>0.014682</td>\n",
       "      <td>0.019881</td>\n",
       "      <td>0.030222</td>\n",
       "      <td>0.087048</td>\n",
       "      <td>0.058625</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.186769</td>\n",
       "      <td>0.450565</td>\n",
       "      <td>0.929293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          6         2      1036       103       114      1.00    1.00.1  \\\n",
       "0  0.000542  0.000000  0.166021  0.037462  0.017251  0.019881  0.020148   \n",
       "1  0.033604  0.133913  0.298530  0.047440  0.029180  0.069583  0.023506   \n",
       "2  0.002710  0.000000  0.372416  0.047063  0.031198  0.049205  0.043318   \n",
       "3  0.022764  0.095652  0.310078  0.045745  0.043494  0.129225  0.077233   \n",
       "4  0.002710  0.001739  0.127826  0.023720  0.014682  0.019881  0.030222   \n",
       "\n",
       "     172076    355965       2.0      6527   1851864        90  \n",
       "0  0.016953  0.023688  0.000709  0.006265  0.504608  0.888889  \n",
       "1  0.194692  0.148439  0.001488  0.016789  0.586036  0.858586  \n",
       "2  0.207614  0.096363  0.000000  0.014868  0.433582  0.818182  \n",
       "3  0.077982  0.293147  0.000850  0.023054  0.451948  0.797980  \n",
       "4  0.087048  0.058625  0.000425  0.186769  0.450565  0.929293  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pré-processamento\n",
    "#   Normalizando os dados\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "normalizador = MinMaxScaler()\n",
    "normalizador.fit(data)\n",
    "\n",
    "dados_normalizados = pd.DataFrame(normalizador.transform(data), columns = data.columns)\n",
    "\n",
    "X = dados_normalizados.drop(columns=' 90')\n",
    "y = dados_normalizados[' 90']\n",
    "\n",
    "XB = data.drop(columns=' 90')\n",
    "yB = data[' 90']\n",
    "\n",
    "dados_normalizados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_trainB, X_testB, y_trainB, y_testB = train_test_split(XB, yB, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>2</th>\n",
       "      <th>1036</th>\n",
       "      <th>103</th>\n",
       "      <th>114</th>\n",
       "      <th>1.00</th>\n",
       "      <th>1.00.1</th>\n",
       "      <th>172076</th>\n",
       "      <th>355965</th>\n",
       "      <th>2.0</th>\n",
       "      <th>6527</th>\n",
       "      <th>1851864</th>\n",
       "      <th>90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.533732</td>\n",
       "      <td>0.191361</td>\n",
       "      <td>0.132867</td>\n",
       "      <td>0.119947</td>\n",
       "      <td>0.140275</td>\n",
       "      <td>0.110956</td>\n",
       "      <td>0.109622</td>\n",
       "      <td>0.081345</td>\n",
       "      <td>0.023375</td>\n",
       "      <td>-0.083173</td>\n",
       "      <td>-0.081262</td>\n",
       "      <td>-0.141385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.533732</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.143375</td>\n",
       "      <td>0.128381</td>\n",
       "      <td>0.101515</td>\n",
       "      <td>0.052496</td>\n",
       "      <td>0.038222</td>\n",
       "      <td>0.117461</td>\n",
       "      <td>0.091423</td>\n",
       "      <td>0.043556</td>\n",
       "      <td>-0.091067</td>\n",
       "      <td>-0.116434</td>\n",
       "      <td>-0.111200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>0.191361</td>\n",
       "      <td>0.143375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.696874</td>\n",
       "      <td>0.619987</td>\n",
       "      <td>0.446753</td>\n",
       "      <td>0.308980</td>\n",
       "      <td>0.352613</td>\n",
       "      <td>0.274442</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>-0.387439</td>\n",
       "      <td>-0.350557</td>\n",
       "      <td>-0.323171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.132867</td>\n",
       "      <td>0.128381</td>\n",
       "      <td>0.696874</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.881073</td>\n",
       "      <td>0.416708</td>\n",
       "      <td>0.164065</td>\n",
       "      <td>0.504415</td>\n",
       "      <td>0.402136</td>\n",
       "      <td>0.041088</td>\n",
       "      <td>-0.286380</td>\n",
       "      <td>-0.301988</td>\n",
       "      <td>-0.332146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.119947</td>\n",
       "      <td>0.101515</td>\n",
       "      <td>0.619987</td>\n",
       "      <td>0.881073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.376871</td>\n",
       "      <td>0.103635</td>\n",
       "      <td>0.333320</td>\n",
       "      <td>0.394490</td>\n",
       "      <td>0.014097</td>\n",
       "      <td>-0.248578</td>\n",
       "      <td>-0.237050</td>\n",
       "      <td>-0.272245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.140275</td>\n",
       "      <td>0.052496</td>\n",
       "      <td>0.446753</td>\n",
       "      <td>0.416708</td>\n",
       "      <td>0.376871</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.763971</td>\n",
       "      <td>0.280953</td>\n",
       "      <td>0.061133</td>\n",
       "      <td>-0.017400</td>\n",
       "      <td>-0.123302</td>\n",
       "      <td>-0.130401</td>\n",
       "      <td>-0.363268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00.1</th>\n",
       "      <td>0.110956</td>\n",
       "      <td>0.038222</td>\n",
       "      <td>0.308980</td>\n",
       "      <td>0.164065</td>\n",
       "      <td>0.103635</td>\n",
       "      <td>0.763971</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.168082</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>-0.006054</td>\n",
       "      <td>-0.158521</td>\n",
       "      <td>-0.153311</td>\n",
       "      <td>-0.288516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172076</th>\n",
       "      <td>0.109622</td>\n",
       "      <td>0.117461</td>\n",
       "      <td>0.352613</td>\n",
       "      <td>0.504415</td>\n",
       "      <td>0.333320</td>\n",
       "      <td>0.280953</td>\n",
       "      <td>0.168082</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.505315</td>\n",
       "      <td>0.131644</td>\n",
       "      <td>-0.149781</td>\n",
       "      <td>-0.220939</td>\n",
       "      <td>-0.329113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355965</th>\n",
       "      <td>0.081345</td>\n",
       "      <td>0.091423</td>\n",
       "      <td>0.274442</td>\n",
       "      <td>0.402136</td>\n",
       "      <td>0.394490</td>\n",
       "      <td>0.061133</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.505315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.191183</td>\n",
       "      <td>-0.149832</td>\n",
       "      <td>-0.226331</td>\n",
       "      <td>-0.289186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.023375</td>\n",
       "      <td>0.043556</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.041088</td>\n",
       "      <td>0.014097</td>\n",
       "      <td>-0.017400</td>\n",
       "      <td>-0.006054</td>\n",
       "      <td>0.131644</td>\n",
       "      <td>0.191183</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.094752</td>\n",
       "      <td>-0.433591</td>\n",
       "      <td>-0.629662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6527</th>\n",
       "      <td>-0.083173</td>\n",
       "      <td>-0.091067</td>\n",
       "      <td>-0.387439</td>\n",
       "      <td>-0.286380</td>\n",
       "      <td>-0.248578</td>\n",
       "      <td>-0.123302</td>\n",
       "      <td>-0.158521</td>\n",
       "      <td>-0.149781</td>\n",
       "      <td>-0.149832</td>\n",
       "      <td>-0.094752</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.572524</td>\n",
       "      <td>0.270294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851864</th>\n",
       "      <td>-0.081262</td>\n",
       "      <td>-0.116434</td>\n",
       "      <td>-0.350557</td>\n",
       "      <td>-0.301988</td>\n",
       "      <td>-0.237050</td>\n",
       "      <td>-0.130401</td>\n",
       "      <td>-0.153311</td>\n",
       "      <td>-0.220939</td>\n",
       "      <td>-0.226331</td>\n",
       "      <td>-0.433591</td>\n",
       "      <td>0.572524</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.678545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>-0.141385</td>\n",
       "      <td>-0.111200</td>\n",
       "      <td>-0.323171</td>\n",
       "      <td>-0.332146</td>\n",
       "      <td>-0.272245</td>\n",
       "      <td>-0.363268</td>\n",
       "      <td>-0.288516</td>\n",
       "      <td>-0.329113</td>\n",
       "      <td>-0.289186</td>\n",
       "      <td>-0.629662</td>\n",
       "      <td>0.270294</td>\n",
       "      <td>0.678545</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 6         2      1036       103       114      1.00  \\\n",
       "6         1.000000  0.533732  0.191361  0.132867  0.119947  0.140275   \n",
       " 2        0.533732  1.000000  0.143375  0.128381  0.101515  0.052496   \n",
       " 1036     0.191361  0.143375  1.000000  0.696874  0.619987  0.446753   \n",
       " 103      0.132867  0.128381  0.696874  1.000000  0.881073  0.416708   \n",
       " 114      0.119947  0.101515  0.619987  0.881073  1.000000  0.376871   \n",
       " 1.00     0.140275  0.052496  0.446753  0.416708  0.376871  1.000000   \n",
       " 1.00.1   0.110956  0.038222  0.308980  0.164065  0.103635  0.763971   \n",
       " 172076   0.109622  0.117461  0.352613  0.504415  0.333320  0.280953   \n",
       " 355965   0.081345  0.091423  0.274442  0.402136  0.394490  0.061133   \n",
       " 2.0      0.023375  0.043556  0.000149  0.041088  0.014097 -0.017400   \n",
       " 6527    -0.083173 -0.091067 -0.387439 -0.286380 -0.248578 -0.123302   \n",
       " 1851864 -0.081262 -0.116434 -0.350557 -0.301988 -0.237050 -0.130401   \n",
       " 90      -0.141385 -0.111200 -0.323171 -0.332146 -0.272245 -0.363268   \n",
       "\n",
       "            1.00.1    172076    355965       2.0      6527   1851864        90  \n",
       "6         0.110956  0.109622  0.081345  0.023375 -0.083173 -0.081262 -0.141385  \n",
       " 2        0.038222  0.117461  0.091423  0.043556 -0.091067 -0.116434 -0.111200  \n",
       " 1036     0.308980  0.352613  0.274442  0.000149 -0.387439 -0.350557 -0.323171  \n",
       " 103      0.164065  0.504415  0.402136  0.041088 -0.286380 -0.301988 -0.332146  \n",
       " 114      0.103635  0.333320  0.394490  0.014097 -0.248578 -0.237050 -0.272245  \n",
       " 1.00     0.763971  0.280953  0.061133 -0.017400 -0.123302 -0.130401 -0.363268  \n",
       " 1.00.1   1.000000  0.168082  0.000717 -0.006054 -0.158521 -0.153311 -0.288516  \n",
       " 172076   0.168082  1.000000  0.505315  0.131644 -0.149781 -0.220939 -0.329113  \n",
       " 355965   0.000717  0.505315  1.000000  0.191183 -0.149832 -0.226331 -0.289186  \n",
       " 2.0     -0.006054  0.131644  0.191183  1.000000 -0.094752 -0.433591 -0.629662  \n",
       " 6527    -0.158521 -0.149781 -0.149832 -0.094752  1.000000  0.572524  0.270294  \n",
       " 1851864 -0.153311 -0.220939 -0.226331 -0.433591  0.572524  1.000000  0.678545  \n",
       " 90      -0.288516 -0.329113 -0.289186 -0.629662  0.270294  0.678545  1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = data.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Multipla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -------------------------------------------------- \n",
      "Com Normalização: r =  0.7222507624946017 \n",
      " -------------------------------------------------- \n",
      "Sem Normalização: rB =  0.7222507624946046 \n",
      " --------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lrB = LinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "lrB.fit(X_trainB, y_trainB)\n",
    "\n",
    "r = lr.score(X_test, y_test)\n",
    "rB = lrB.score(X_testB, y_testB)\n",
    "\n",
    "print('',\"-\"*50, '\\nCom Normalização: r = ', r, '\\n', '-'*50, '\\nSem Normalização: rB = ', rB, '\\n', '-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "X = dados_normalizados[' 1851864']\n",
    "y = dados_normalizados[' 90']\n",
    "\n",
    "X = np.reshape(X, (-1,1))\n",
    "y = np.reshape(y, (-1,1)).ravel()\n",
    "\n",
    "XB = data[' 1851864']\n",
    "yB = data[' 90']\n",
    "\n",
    "XB = np.reshape(XB, (-1,1))\n",
    "yB = np.reshape(yB, (-1,1)).ravel()\n",
    "# Separando os dados para o treinamento\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_trainB, X_testB, y_trainB, y_testB = train_test_split(XB, yB, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -------------------------------------------------- \n",
      "Com Normalização: r =  0.41122258208392515 \n",
      " -------------------------------------------------- \n",
      "Sem Normalização: rB =  0.41122258208392504 \n",
      " --------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lrB = LinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "lrB.fit(X_trainB, y_trainB)\n",
    "\n",
    "r = lr.score(X_test, y_test)\n",
    "rB = lrB.score(X_testB, y_testB)\n",
    "\n",
    "print('',\"-\"*50, '\\nCom Normalização: r = ', r, '\\n', '-'*50, '\\nSem Normalização: rB = ', rB, '\\n', '-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "X = dados_normalizados[' 1851864']\n",
    "y = dados_normalizados[' 90']\n",
    "\n",
    "X = np.reshape(X, (-1,1))\n",
    "y = np.reshape(y, (-1,1)).ravel()\n",
    "\n",
    "XB = data[' 1851864']\n",
    "yB = data[' 90']\n",
    "\n",
    "XB = np.reshape(XB, (-1,1))\n",
    "yB = np.reshape(yB, (-1,1)).ravel()\n",
    "# Separando os dados para o treinamento\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_trainB, X_testB, y_trainB, y_testB = train_test_split(XB, yB, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -------------------------------------------------- \n",
      "Com Normalização: r =  0.7580785394552714 \n",
      " -------------------------------------------------- \n",
      "Sem Normalização: rB =  0.7739751745383646 \n",
      " --------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = SVR(kernel= 'rbf')\n",
    "svrB = SVR(kernel= 'rbf')\n",
    "\n",
    "svr.fit(X_train, y_train)\n",
    "svrB.fit(X_trainB, y_trainB)\n",
    "\n",
    "\n",
    "r = svr.score(X_test, y_test)\n",
    "rB = svrB.score(X_testB, y_testB)\n",
    "\n",
    "print('',\"-\"*50, '\\nCom Normalização: r = ', r, '\\n', '-'*50, '\\nSem Normalização: rB = ', rB, '\\n', '-'*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
